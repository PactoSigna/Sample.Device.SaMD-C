---
id: SDD-001
title: Detection Engine Module Design
status: approved
author: rune@ords.io
reviewers:
  - quality
approvers:
  - engineering-lead
---

# Detailed Design: Detection Engine Module

**Implements:** [HLD-001](../architecture/HLD-001.md)

## Overview

The Detection Engine is the core processing module that analyzes ECG data for atrial fibrillation. This document details the internal design of the module.

## Module Structure

```
detection-engine/
├── src/
│   ├── preprocessor.py       # Signal preprocessing
│   ├── qrs_detector.py       # R-peak detection
│   ├── rr_analyzer.py        # R-R interval analysis
│   ├── quality_assessor.py   # Signal quality check
│   ├── afib_classifier.py    # ML classification
│   └── engine.py             # Main orchestrator
└── models/
    └── afib_model_v2.onnx    # Trained model
```

## Processing Pipeline

### 1. Signal Preprocessing

```python
def preprocess(ecg_signal: np.ndarray) -> np.ndarray:
    # Bandpass filter: 0.5-40 Hz
    filtered = bandpass_filter(ecg_signal, low=0.5, high=40)
    # Baseline wander removal
    detrended = remove_baseline(filtered)
    return detrended
```

### 2. QRS Detection

- Algorithm: Pan-Tompkins
- Output: Array of R-peak indices
- Accuracy requirement: >99% detection rate

### 3. R-R Interval Calculation

```python
def calculate_rr_intervals(r_peaks: np.ndarray, fs: int) -> np.ndarray:
    intervals_samples = np.diff(r_peaks)
    intervals_ms = (intervals_samples / fs) * 1000
    return intervals_ms
```

### 4. Signal Quality Assessment

- Metric: Signal-to-noise ratio (SNR)
- Threshold: 10 dB minimum
- Method: Power spectral density analysis

### 5. AFib Classification

- Model: ONNX neural network
- Input: 60-second R-R interval window
- Output: Probability [0.0, 1.0]
- Threshold: ≥0.5 for AFib positive

## Error Handling

| Error                   | Handling                         |
| ----------------------- | -------------------------------- |
| Insufficient data       | Return "incomplete" status       |
| Poor signal quality     | Suppress result, flag quality    |
| Model inference failure | Log error, return "error" status |

## Performance Considerations

- Batch processing for efficiency
- Model inference: <100ms per segment
- Total pipeline: <2000ms requirement
